[
["index.html", "Welcome to the Documentation! Preface Hello World!", " Welcome to the Documentation! Authors Names Here 12/19/2019 Preface Hello World! This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 "],
["data-prep-management.html", "1 Data Prep &amp; Management 1.1 EPA Pollution Data 1.2 FAA Weather Data", " 1 Data Prep &amp; Management This project uses weather and pollution data from remotely sensed satellite imagery, but also ground based sensors maintained by the EPA and FAA to model air quality in the Midwest. Using the ground sensors, the team can attempt to predict pollutions levels based on satellite data. This chapter focuses on how weather and pollution data from ground sensors was downloaded and prepared for use in refining the prediction. 1.1 EPA Pollution Data EPA data was seamlessly imported into R using the aqsr package by Joshua P. Keller at Colorado State University. The package takes advanatge of the EPA AQS DataMart API to load data in R as data.frame objects with only a couple lines of code. It allows users to query for sensor data across multiple air quality variables, geographies, and timeframes. Let’s get started by downloading the package. devtools::install_github(&quot;jpkeller/aqsr&quot;) library(aqsr) 1.1.1 Getting Started This section describes the process for querying EPA sensor data using the aqsr package. For more information on how each function works, please reference the package documentation. Obtaining an API Key For first time users of the AQS DataMart API, you must first register your email to recieve an API key. (Users who already have a DataMart API key, please skep to the next step). The API key is a required input for all querying functions in the aqsr package. Obtaining a key is made simple by calling the aqs_signup() function and inputting your own email address. aqs_signup(&#39;YourEmailHere@uchicago.edu&#39;) Save your API key from the email confirmation for future reference. In case you don’t recieve an email, verify that your email address was typed correctly, and check your spam folder. 1.1.1.1 Using your API Key in aqsr Setup your AQI key with the aqr package by using the create_user() function. This way, you won’t have to keep typing your email and API key each time you query for data. myuser = create_user(email = &#39;YourEmailHere@uchicago.edu&#39;, key = &#39;apikey123&#39;) 1.1.2 PM2.5 Data Query This section describes how to query for PM2.5 concetration data from EPA pollution sensors. We are looking for at PM2.5 data Wisconsin, Illinois, and Indiana between 2014 and 2018 for our project. First, let’s start small and query only for Illinois data for the first week of 2018. IL.data = aqs_dailyData_byState(aqs_user = myuser, # Previously defined user emailand API key param = 88101, # EPA AQS Parameter Code for PM2.5 bdate = &quot;20180101&quot;, # Starting Date (Jan 1st ,2018) edate = &quot;20180107&quot;, # Ending Date (Jan 7th, 2018) state = &quot;17&quot;) # State FIPS Code for Illinois IL.data[1,] ## state_code county_code site_number parameter_code poc latitude longitude ## 2 17 115 0013 88101 3 39.86683 -88.92559 ## datum parameter sample_duration pollutant_standard date_local ## 2 WGS84 PM2.5 - Local Conditions 1 HOUR &lt;NA&gt; 2018-01-01 ## units_of_measure event_type observation_count observation_percent ## 2 Micrograms/cubic meter (LC) None 24 100 ## validity_indicator arithmetic_mean first_max_value first_max_hour aqi ## 2 Y 9.5625 20.6 1 NA ## method_code method ## 2 183 Thermo Scientific 5014i or FH62C14-DHS w/VSCC - Beta Attenuation ## local_site_name site_address state county city cbsa_code cbsa ## 2 IEPA TRAILER 2200 N. 22ND Illinois Macon Decatur 19500 Decatur, IL ## date_of_last_change ## 2 2019-01-24 The outputted data frame includes many fields regarding the PM2.5 observation, including spatial data for the sensor’s location. We will focus on these details later on in our data wrangling process. The next code chunk describes how to query for PM2.5 data across our three states and four years. library(dplyr) # List of States to Iterate Through states = c(&quot;17&quot;, &quot;18&quot;, &quot;55&quot;) # Matrix of Start Dates and End Dates to Iterate Through dates = matrix(c(&quot;20140101&quot;, &quot;20141231&quot;, &quot;20150101&quot;, &quot;20151231&quot;, &quot;20160101&quot;, &quot;20161231&quot;, &quot;20170101&quot;, &quot;20171231&quot;, &quot;20180101&quot;, &quot;20181231&quot;), ncol = 2, byrow = TRUE) # Leveraging apply functions to iterate through both states and dates full.data = lapply(states, function(x){ mapply(aqs_dailyData_byState, bdate = dates[,1], edate = dates[,2], MoreArgs = list(aqs_user = myuser, param = 88101, state = x), SIMPLIFY = FALSE ) %&gt;% do.call(&quot;rbind&quot;, .) }) %&gt;% do.call(&quot;rbind&quot;, .) 1.2 FAA Weather Data FAA weather data gathered from the Automated Surface Observing System (ASOS) can be imported using the riem package. This package, created by ROpenSci, queries weather data from the Iowa Environmental Mesonet, an online portal for international ASOS data maintained by Iowa State University. First, let’s load the package. devtools::install_github(&#39;ropensci/riem&#39;) ## Skipping install of &#39;riem&#39; from a github remote, the SHA1 (ea0f082d) has not changed since last install. ## Use `force = TRUE` to force installation library(riem, quietly = TRUE) 1.2.1 Sample Query Below is an R code snippet that performs the simplest weather data query possible in the riem package. It specifies a particular weather station using an airport code and a date range to query for. The output is a tibble table of raw ASOS weather data. The code snippet below extracts sensor data at the San Francisco International Airport. SFO.weather = riem_measures(station = &#39;KSFO&#39;, date_start = &quot;2014-01-01&quot;, date_end = &#39;2014-01-02&#39;) head(SFO.weather) ## # A tibble: 6 x 31 ## station valid lon lat tmpf dwpf relh drct sknt p01i ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SFO 2014-01-01 00:56:00 -122. 37.6 54.0 43.0 66.3 290 8 0 ## 2 SFO 2014-01-01 01:56:00 -122. 37.6 52.0 43.0 71.3 280 9 0 ## 3 SFO 2014-01-01 02:56:00 -122. 37.6 51.1 44.1 76.8 290 8 0 ## 4 SFO 2014-01-01 03:56:00 -122. 37.6 48.9 37.9 65.7 0 0 0 ## 5 SFO 2014-01-01 04:56:00 -122. 37.6 50 39.9 68.2 0 0 0 ## 6 SFO 2014-01-01 05:56:00 -122. 37.6 48.9 37.0 63.4 0 0 0 ## # … with 21 more variables: alti &lt;dbl&gt;, mslp &lt;dbl&gt;, vsby &lt;dbl&gt;, gust &lt;lgl&gt;, ## # skyc1 &lt;chr&gt;, skyc2 &lt;chr&gt;, skyc3 &lt;chr&gt;, skyc4 &lt;lgl&gt;, skyl1 &lt;dbl&gt;, ## # skyl2 &lt;dbl&gt;, skyl3 &lt;dbl&gt;, skyl4 &lt;lgl&gt;, wxcodes &lt;lgl&gt;, ## # ice_accretion_1hr &lt;lgl&gt;, ice_accretion_3hr &lt;lgl&gt;, ice_accretion_6hr &lt;lgl&gt;, ## # peak_wind_gust &lt;lgl&gt;, peak_wind_drct &lt;lgl&gt;, peak_wind_time &lt;lgl&gt;, ## # feel &lt;dbl&gt;, metar &lt;chr&gt; The outputted table shows weather data for a 24-hour period on January 1st, 2014 at the San Francisco International Airport. The valid column species when each weather report was generated, typically at 1-hour intervals. The tmpf and dwpf columns give the ambient air temperature and dew point in Fahrenheit (ºF). Other important variables in our project include air pressure (alti), measured in inches of mercury (in.Hg), and visibility (vsby) in miles. For more information on all available varibles, see Iowa State’s Documentation. Next, we will apply this function at a large scare across multiple sensors and timescales. 1.2.2 Finding ASOS Sensors The FAA collects weather data at hourly intervals for each meteorological station, with some stations providing half-hour intervals. Even querying for short periods of time can yield large amounts of data. To optimise performance, we want to only query data from stations in our study area. Finding Sensors by State In our project, we focus on certain counties in Illinois, Indiana, and Wisconsin, so we are interested in finding the sensors within that study area. The first step is to query the locations of all weather stations in the three states using the riem package. In the example below, we query for sensors in the Illinois ASOS sensor network. riem_stations(network = &#39;IL_ASOS&#39;)[1:3,] ## # A tibble: 3 x 4 ## id name lon lat ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ALN ALTON/ST LOUIS R -90.0 38.9 ## 2 BMI BLOOMINGTON/NORM -88.9 40.5 ## 3 CPS CAHOKIA/ST LOUIS -90.2 38.6 To query for data across multiple states, we are going the apply the riem_stations function to a list of weather station networks, as shown below. networks = list(&#39;IL_ASOS&#39;, &#39;IN_ASOS&#39;, &#39;WI_ASOS&#39;) library(dplyr, quietly = TRUE) station.locs = lapply(networks, riem::riem_stations) %&gt;% do.call(rbind, .) # Creates a single data table as output Note: You can find a list of state abbreviations by typing ‘state.abb’ in your R console. Converting Latitude and Longitude Coordinates to Spatial Data The data tables returned by the riem package must be converted to spatial data to determine which sensors are located in the study area. Since the lon/lat coordinates are already provided, the data table is easily converted to a spatial sf object. station.locs.sf = sf::st_as_sf(station.locs, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) # Plot stations and study area boundaries to verify that the correct sensors were selected plot(station.locs.sf$geometry) plot(sf::st_read(&#39;https://uchicago.box.com/shared/static/uw0srt8nyyjfqo6l0dv07cyskwmv6r50.geojson&#39;, quiet = TRUE)$geometry, border = &#39;red&#39;, add = TRUE) We plot to results to verify that our query and data conversion process worked correctly. For reference, the boundaires of the study area is outlined in red. Selecting Sensors within our Study Area Next, we perform a spatial join to only keep the points located within the boundaries of our study area polygons. The spatial join is completed by the sf package, as shown below. For more information regarding spatial joins and spatial predicates, please see this helpful blog post by GISgeography.com. # Loading study area boundaries study.area = sf::st_read(&#39;https://uchicago.box.com/shared/static/uw0srt8nyyjfqo6l0dv07cyskwmv6r50.geojson&#39;, quiet = TRUE) study.sensors = sf::st_join(station.locs.sf, study.area, left = FALSE) # Verify Spatial Join by Plotting plot(study.area$geometry, border = &#39;red&#39;) plot(study.sensors$geometry, add = TRUE) title(&#39;Weather Stations Within the Study Area&#39;) Now that we have a dataset of which weather stations we are interested in, we can query for the weather data associated with each station. 1.2.3 Weather Data Query Again we use the lapply function in base R to execute the riem_measures function on a list of sensor IDs. This allows us to iteratively query for weather data from each individual sensor in a list. In the code snippet below, we take the study sensors obtained previously and query for a single day’s worth of weather data. library(dplyr, quietly = TRUE) weather.data = lapply(study.sensors$id, function(x){riem::riem_measures(x, date_start = &quot;2014-01-01&quot;, date_end = &quot;2014-01-02&quot;)}) %&gt;% do.call(rbind, .) # Creates a single data table as output ## Warning: No results for this query. ## Warning: No results for this query. ## Warning: No results for this query. weather.data[1:3,] ## # A tibble: 3 x 31 ## station valid lon lat tmpf dwpf relh drct sknt p01i ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MDW 2014-01-01 00:49:00 -87.8 41.8 12.2 8.6 85.2 230 3 0.01 ## 2 MDW 2014-01-01 00:51:00 -87.8 41.8 12.9 8.96 83.8 230 3 0.01 ## 3 MDW 2014-01-01 01:51:00 -87.8 41.8 12.9 8.96 83.8 280 3 0.0001 ## # … with 21 more variables: alti &lt;dbl&gt;, mslp &lt;dbl&gt;, vsby &lt;dbl&gt;, gust &lt;dbl&gt;, ## # skyc1 &lt;chr&gt;, skyc2 &lt;chr&gt;, skyc3 &lt;chr&gt;, skyc4 &lt;lgl&gt;, skyl1 &lt;dbl&gt;, ## # skyl2 &lt;dbl&gt;, skyl3 &lt;dbl&gt;, skyl4 &lt;lgl&gt;, wxcodes &lt;chr&gt;, ## # ice_accretion_1hr &lt;dbl&gt;, ice_accretion_3hr &lt;lgl&gt;, ice_accretion_6hr &lt;dbl&gt;, ## # peak_wind_gust &lt;lgl&gt;, peak_wind_drct &lt;lgl&gt;, peak_wind_time &lt;lgl&gt;, ## # feel &lt;dbl&gt;, metar &lt;chr&gt; Querying Full Weather Dataset Use caution when querying for a large amount of data. Data tables can easily become unwieldy after querying for a large number of weather stations across a wide time scale. The code snippet below downloads all ASOS weather data for sensors in our study area from January 1st 2014 to December 31st 2018, which is our study time period. It has approximately 4.8 Million records and takes 6-10 minutes to download. weather.data = lapply(study.sensors$id, function(x){riem::riem_measures(x, date_start = &quot;2014-01-01&quot;, date_end = &quot;2018-12-31&quot;)}) %&gt;% do.call(rbind, .) # Creates a single data table as output "],
["merging-satellite-and-point-sensor.html", "2 Merging Satellite and Point Sensor 2.1 Generate Rasters 2.2 Export to CSV", " 2 Merging Satellite and Point Sensor There’s a fundamental challenge in our project to merge AOD data and predictor variables because the data capture techniques are very different. The satelite-based AOD data is measured continously across the surface of the earth on a 1km by 1km grid system. Meanwhile, sensor data is only captured locally at the sensor location. Therefore, a method to interpolate local sensor data to generate a continuous surface of data is required. An ‘Optimized’ IDW interpolation was used to estimate sensor values across a 1km by 1km grid system. This method takes into account the sensor locations and value for each variable to estimate values in grid cells without a sensor based on a linear interpolation of nearby sensor values. The specific number of sensors to take into account and the distance decay power function were optimized by minimizing the RMSE (Error). This method was adapted from an RSpatial Tutorial on IDW interpolation with pollution and weather data. To simplify implementation and replication, the entire workflow was coded in R and bundled into a packaged named sensor2raster. The next sections demonstrate how to apply this package to sensor data. devtools::install_url(&#39;https://uchicago.box.com/shared/static/rtt6ofsm2j9dgob2qykck5yda0c89ayl.tar.gz&#39;) library(sensor2raster) 2.1 Generate Rasters 2.2 Export to CSV "]
]
